{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271aada7-bbe5-4f2c-be0e-d3904ae9d1fc",
   "metadata": {},
   "source": [
    "The hyperparameters of a machine learning model are parameters that are not learned from data. They should be set prior to fitting the model to the training set. In this chapter, you'll learn how to tune the hyperparameters of a tree-based model using grid search cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0bb309-94b0-40cd-8f45-bb6b250fe8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing course packages; you can add more too!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# Importing course datasets as DataFrames\n",
    "auto = pd.read_csv('../datasets/auto.csv')\n",
    "bikes = pd.read_csv('../datasets/bikes.csv')\n",
    "liver_disease = pd.read_csv('../datasets/indian_liver_patient_preprocessed.csv', index_col=0)\n",
    "wbc = pd.read_csv('../datasets/wbc.csv') # Wisconsin Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c930bf-d63a-4454-b7ff-6709c0f3dace",
   "metadata": {},
   "source": [
    "# Tuning a CART's Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd71aea-7e03-4cb7-b80d-a3c4aa849c39",
   "metadata": {},
   "source": [
    "### Set the tree's hyperparameter grid\n",
    "\n",
    "In this exercise, you'll manually set the grid of hyperparameters that will be used to tune the classification tree dt and find the optimal classifier in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a4cfba-da6f-4eca-b98e-680022675372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth':[2,3,4],'min_samples_leaf':[0.12, 0.14, 0.16, 0.18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b936eb-4d9f-443d-acc9-faf667195b52",
   "metadata": {},
   "source": [
    "### Search for the optimal tree\n",
    "\n",
    "In this exercise, you'll perform grid search using 5-fold cross validation to find dt's optimal hyperparameters. Note that because grid search is an exhaustive process, it may take a lot time to train the model. Here you'll only be instantiating the ```GridSearchCV``` object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the ```.fit()``` method:\n",
    "\n",
    "```grid_object.fit(X_train, y_train)```\n",
    "\n",
    "An untuned classification tree ```dt``` as well as the dictionary ```params_dt``` that you defined in the previous exercise are available in your workspace.\n",
    "\n",
    "[sklearn.model_selection.GridSearchCV\n",
    " Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20883e27-f143-4fff-83b2-6efccf7085ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREP ENVIRONMENT FOR LESSON\n",
    "\n",
    "# re instantiate the training/test data to include all 30 columns.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create arrays for features and target variable\n",
    "y = liver_disease['Liver_disease'] # target\n",
    "X = liver_disease.drop('Liver_disease', axis='columns')\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "SEED=1\n",
    "dt = DecisionTreeClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416388d3-e9c3-4d52-89fe-5f432a973f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9957f-405f-4e16-9513-6438053d16fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate the optimal tree\n",
    "\n",
    "In this exercise, you'll evaluate the test set ROC AUC score of grid_dt's optimal model.\n",
    "\n",
    "In order to do so, you will first determine the probability of obtaining the positive label for each test set observation. You can use the ```methodpredict_proba()``` of an sklearn classifier to compute a 2D array containing the probabilities of the negative and positive class-labels respectively along columns.\n",
    "\n",
    "The dataset is already loaded and processed for you (numerical features are standardized); it is split into 80% train and 20% test. ```X_test```, ```y_test``` are available in your workspace. In addition, we have also loaded the trained ```GridSearchCV``` object ```grid_dt``` that you instantiated in the previous exercise. Note that ```grid_dt``` was trained as follows:\n",
    "\n",
    "```grid_dt.fit(X_train, y_train)```\n",
    "\n",
    "[sklearn.metrics.roc_auc_score Documentation()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b445438-4d44-4e1c-8cf1-6cf3d825cda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit your model to the training data in preparation for the next cell.\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c70093-6fc2-4540-ad13-e7d87a9800ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.677\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9642645e-b42e-4565-888d-e789d98a9f76",
   "metadata": {},
   "source": [
    "# Tuning a RF's Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24ea5e-a0f1-4ed8-ae61-be5aa8bf5b12",
   "metadata": {},
   "source": [
    "### Set the hyperparameter grid of RF\n",
    "\n",
    "In this exercise, you'll manually set the grid of hyperparameters that will be used to tune rf's hyperparameters and find the optimal regressor. For this purpose, you will be constructing a grid of hyperparameters and tune the number of estimators, the maximum number of features used when splitting each node and the minimum number of samples (or fraction) per leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d969a08-87ae-4b41-b453-28c0270a99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {'n_estimators':[100, 350, 500], 'max_features':['log2', 'auto', 'sqrt'],'min_samples_leaf':[2, 10, 30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9416cdf-de5e-4203-a931-8b85c5249008",
   "metadata": {},
   "source": [
    "### Search for the optimal forest\n",
    "\n",
    "In this exercise, you'll perform grid search using 3-fold cross validation to find rf's optimal hyperparameters. To evaluate each model in the grid, you'll be using the negative mean squared error metric.\n",
    "\n",
    "Note that because grid search is an exhaustive search process, it may take a lot time to train the model. Here you'll only be instantiating the ```GridSearchCV``` object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the ```.fit()``` method:\n",
    "\n",
    "```grid_object.fit(X_train, y_train)```\n",
    "\n",
    "The untuned random forests regressor model ```rf``` as well as the dictionary ```params_rf``` that you defined in the previous exercise are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d359e2d-d2d6-4090-bceb-bb58290ef39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREP ENVIRONMENT FOR LESSON\n",
    "\n",
    "# re instantiate the training/test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import RandomForestRegressor from sklearn.tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create arrays for features and target variable\n",
    "y = bikes['cnt'] # target\n",
    "X = bikes.drop('cnt', axis='columns')\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "SEED=1\n",
    "rf = RandomForestRegressor(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066bbaea-1ac5-4bc0-b61c-c94a7d4a3651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03b1a9-f9e1-4c14-8e1a-bb86b150a763",
   "metadata": {},
   "source": [
    "### Evaluate the optimal forest\n",
    "\n",
    "In this last exercise of the course, you'll evaluate the test set RMSE of grid_rf's optimal model.\n",
    "\n",
    "The dataset is already loaded and processed for you and is split into 80% train and 20% test. In your environment are available ```X_test```, ```y_test``` and the function mean_squared_error from ```sklearn.metrics``` under the alias ```MSE```. In addition, we have also loaded the trained ```GridSearchCV``` object grid_rf that you instantiated in the previous exercise. Note that ```grid_rf``` was trained as follows:\n",
    "\n",
    "```grid_rf.fit(X_train, y_train)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2773240f-3d83-4fd5-9fe5-1e9894e004d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit your model to the training data in preparation for the next cell.\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0474b98a-2963-4612-8c26-69c7bdc4c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 59.200\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fcae0-29a7-4736-8432-0c282351c759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
