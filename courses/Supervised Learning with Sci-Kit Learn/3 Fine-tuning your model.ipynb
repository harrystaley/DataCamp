{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ef4758-4db8-40cd-a75d-054293b7ceef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0              6      148         72       35        0  33.6  0.627   50   \n",
       "1              1       85         66       29        0  26.6  0.351   31   \n",
       "2              8      183         64        0        0  23.3  0.672   32   \n",
       "3              1       89         66       23       94  28.1  0.167   21   \n",
       "4              0      137         40       35      168  43.1  2.288   33   \n",
       "..           ...      ...        ...      ...      ...   ...    ...  ...   \n",
       "763           10      101         76       48      180  32.9  0.171   63   \n",
       "764            2      122         70       27        0  36.8  0.340   27   \n",
       "765            5      121         72       23      112  26.2  0.245   30   \n",
       "766            1      126         60        0        0  30.1  0.349   47   \n",
       "767            1       93         70       31        0  30.4  0.315   23   \n",
       "\n",
       "     diabetes  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "..        ...  \n",
       "763         0  \n",
       "764         0  \n",
       "765         0  \n",
       "766         1  \n",
       "767         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the course packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "\n",
    "# Import the course datasets as DataFrames\n",
    "auto = pd.read_csv(\"../datasets/auto.csv\")\n",
    "boston = pd.read_csv(\"../datasets/boston.csv\")\n",
    "diabetes = pd.read_csv(\"../datasets/diabetes.csv\")\n",
    "gapminder = pd.read_csv(\"../datasets/gm_2008_region.csv\")\n",
    "votes = pd.read_csv(\"../datasets/votes.csv\")\n",
    "whitewine = pd.read_csv(\"../datasets/white-wine.csv\")\n",
    "\n",
    "# Preview the first DataFrame\n",
    "diabetes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f96947-08d4-4ea5-899a-16c45086e42d",
   "metadata": {},
   "source": [
    "# How good is your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a9564-ec68-4f21-9bd5-5aa0f645dc39",
   "metadata": {},
   "source": [
    "### Metrics for classification\n",
    "\n",
    "Train a knn classafication model in order to preduct diabetes in the PIMA people and produce a confusion matrix and classification report.\n",
    "\n",
    "Confusion matrix:\n",
    "\n",
    "| Predicted: Diabetes Positive | Predicted: Diabetes Negative |\n",
    "|---|---|\n",
    "| True Positive | False Negative |\n",
    "| False Positive | True Negative |\n",
    "\n",
    "Accuracy:  $\\frac{tp+tn}{tp+tn+fp+fn}$\n",
    "\n",
    "Precision:  $\\frac{tp}{tp+fp}$\n",
    "\n",
    "Recall:  $\\frac{tp}{tp+fn}$\n",
    "\n",
    "F1 Score: $2*\\frac{Precision*Recall}{Precision+Recall}$\n",
    "\n",
    "High precision: Not many positive dianoses of diabetes predicted incorrectly, precision is also referred to as positive predictive value (PPV)\n",
    "\n",
    "High recall: Predicted most diagnoses correctly, Recall in this context is also referred to as the true positive rate or sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed562e6-df95-4776-b783-0d0c86ca75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X =  diabetes.drop('diabetes', axis=1).values # features\n",
    "y = diabetes['diabetes'].values # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb24aa4-dfae-4849-9e15-5e3fd3e5a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  30]\n",
      " [ 56  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       206\n",
      "           1       0.61      0.45      0.52       102\n",
      "\n",
      "    accuracy                           0.72       308\n",
      "   macro avg       0.68      0.65      0.66       308\n",
      "weighted avg       0.71      0.72      0.71       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0898ce-24d3-4153-be73-92dfa35efc93",
   "metadata": {},
   "source": [
    "# Logistic regression and the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed956e1a-1574-476a-9c78-9fdb2dd2df86",
   "metadata": {},
   "source": [
    "### Building a logistic regression model\n",
    "\n",
    "Train a logistic regression model on exactly the same data as in the previous exercise. Will it outperform k-NN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4bad56-fc3b-4f86-a3ad-a4d50458e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168  38]\n",
      " [ 36  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       206\n",
      "           1       0.63      0.65      0.64       102\n",
      "\n",
      "    accuracy                           0.76       308\n",
      "   macro avg       0.73      0.73      0.73       308\n",
      "weighted avg       0.76      0.76      0.76       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression(max_iter=500) # changed max_iter to 500 to avoid an error.\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7640e-f601-4169-8507-4e95e0d5f96d",
   "metadata": {},
   "source": [
    "### Plotting an ROC curve\n",
    "\n",
    "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers starting in 1941, which led to its name.\n",
    "\n",
    "The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection. The false-positive rate is also known as probability of false alarm and can be calculated as (1 − specificity). It can also be thought of as a plot of the power as a function of the Type I Error of the decision rule (when the performance is calculated from just a sample of the population, it can be thought of as estimators of these quantities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3f591d-7b7f-43ca-b2d2-8cdc8fb300ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c6e95-e45c-4bea-a90b-990dc7311fce",
   "metadata": {},
   "source": [
    "# Area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d87ef5-ffb8-4f13-87e6-4f33e6b08b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8243384732533791\n",
      "AUC scores computed using 5-fold cross-validation: [0.81240741 0.80777778 0.82555556 0.87283019 0.84471698]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(logreg ,X, y, scoring='roc_auc', cv=5)\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430dc2d-0590-4ef3-821d-5679829d4b2f",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccdc902-6ae7-4d05-b681-9c285f8acd4c",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8d2a22-4087-43ea-84e4-3010f5adfc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.006105402296585327}\n",
      "Best score is 0.7734742381801205\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(max_iter=500) # changed max iter to 500 to avoid an error.\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6024e-0c84-4f4e-a077-0f5331d27a01",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8c00cc-9e40-4b04-8a47-5b78fbc3c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 3, 'max_features': 8, 'min_samples_leaf': 5}\n",
      "Best score is 0.7291740938799762\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc86f1-28f1-4eb4-a45f-42b7188d3a3d",
   "metadata": {},
   "source": [
    "# Hold-out set for final evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d38c20-68af-48cc-8e66-86159418d298",
   "metadata": {},
   "source": [
    "### Hold-out set in practice I: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f0064a-64ad-4e69-95bc-6a7b15e583f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 0.0007196856730011522, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.7630434782608695\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l2']} # l2 penalty is not supported.\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c511f98-c82b-4310-b9de-3d2169007e66",
   "metadata": {},
   "source": [
    "### Hold-out set in practice II: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b07518-68c4-43d9-87d7-891f600261ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ElasticNet l1 ratio: {'l1_ratio': 0.0}\n",
      "Tuned ElasticNet R squared: 0.24765337510702734\n",
      "Tuned ElasticNet MSE: 0.16664179543611005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.73301859157129, tolerance: 0.008436684782608696\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.920050137052524, tolerance: 0.008285869565217392\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.69617864870432, tolerance: 0.00867391304347826\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.98810582589104, tolerance: 0.008520652173913044\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.475795732558645, tolerance: 0.00849320652173913\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.87629751791526, tolerance: 0.010609565217391308\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "param_grid = {'l1_ratio': l1_space}\n",
    "\n",
    "# Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "gm_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and compute metrics\n",
    "y_pred = gm_cv.predict(X_test)\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "print(\"Tuned ElasticNet MSE: {}\".format(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710d878-6793-4b9e-8fc8-929813816fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
